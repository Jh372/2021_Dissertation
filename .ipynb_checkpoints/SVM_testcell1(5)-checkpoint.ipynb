{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "turned-extra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model\n",
      "Output data192.csv[1/160]\n",
      "Output data117.csv[2/160]\n",
      "Output data196.csv[3/160]\n",
      "Output data172.csv[4/160]\n",
      "Output data155.csv[5/160]\n",
      "Output data64.csv[6/160]\n",
      "Output data111.csv[7/160]\n",
      "Output data156.csv[8/160]\n",
      "Output data95.csv[9/160]\n",
      "Output data176.csv[10/160]\n",
      "Output data159.csv[11/160]\n",
      "Output data200.csv[12/160]\n",
      "Output data45.csv[13/160]\n",
      "Output data157.csv[14/160]\n",
      "Output data151.csv[15/160]\n",
      "Output data83.csv[16/160]\n",
      "Output data7.csv[17/160]\n",
      "Output data147.csv[18/160]\n",
      "Output data1.csv[19/160]\n",
      "Output data140.csv[20/160]\n",
      "Output data49.csv[21/160]\n",
      "Output data78.csv[22/160]\n",
      "Output data5.csv[23/160]\n",
      "Output data189.csv[24/160]\n",
      "Output data173.csv[25/160]\n",
      "Output data72.csv[26/160]\n",
      "Output data191.csv[27/160]\n",
      "Output data80.csv[28/160]\n",
      "Output data171.csv[29/160]\n",
      "Output data96.csv[30/160]\n",
      "Output data174.csv[31/160]\n",
      "Output data127.csv[32/160]\n",
      "Output data20.csv[33/160]\n",
      "Output data8.csv[34/160]\n",
      "Output data74.csv[35/160]\n",
      "Output data84.csv[36/160]\n",
      "Output data195.csv[37/160]\n",
      "Output data66.csv[38/160]\n",
      "Output data87.csv[39/160]\n",
      "Output data128.csv[40/160]\n",
      "Output data106.csv[41/160]\n",
      "Output data153.csv[42/160]\n",
      "Output data4.csv[43/160]\n",
      "Output data88.csv[44/160]\n",
      "Output data101.csv[45/160]\n",
      "Output data112.csv[46/160]\n",
      "Output data178.csv[47/160]\n",
      "Output data109.csv[48/160]\n",
      "Output data33.csv[49/160]\n",
      "Output data148.csv[50/160]\n",
      "Output data27.csv[51/160]\n",
      "Output data90.csv[52/160]\n",
      "Output data102.csv[53/160]\n",
      "Output data145.csv[54/160]\n",
      "Output data9.csv[55/160]\n",
      "Output data77.csv[56/160]\n",
      "Output data185.csv[57/160]\n",
      "Output data105.csv[58/160]\n",
      "Output data28.csv[59/160]\n",
      "Output data11.csv[60/160]\n",
      "Output data144.csv[61/160]\n",
      "Output data152.csv[62/160]\n",
      "Output data160.csv[63/160]\n",
      "Output data169.csv[64/160]\n",
      "Output data32.csv[65/160]\n",
      "Output data104.csv[66/160]\n",
      "Output data94.csv[67/160]\n",
      "Output data154.csv[68/160]\n",
      "Output data108.csv[69/160]\n",
      "Output data131.csv[70/160]\n",
      "Output data138.csv[71/160]\n",
      "Output data110.csv[72/160]\n",
      "Output data158.csv[73/160]\n",
      "Output data162.csv[74/160]\n",
      "Output data150.csv[75/160]\n",
      "Output data183.csv[76/160]\n",
      "Output data149.csv[77/160]\n",
      "Output data107.csv[78/160]\n",
      "Output data89.csv[79/160]\n",
      "Output data55.csv[80/160]\n",
      "Output data14.csv[81/160]\n",
      "Output data93.csv[82/160]\n",
      "Output data139.csv[83/160]\n",
      "Output data85.csv[84/160]\n",
      "Output data53.csv[85/160]\n",
      "Output data119.csv[86/160]\n",
      "Output data118.csv[87/160]\n",
      "Output data143.csv[88/160]\n",
      "Output data199.csv[89/160]\n",
      "Output data175.csv[90/160]\n",
      "Output data170.csv[91/160]\n",
      "Output data167.csv[92/160]\n",
      "Output data82.csv[93/160]\n",
      "Output data115.csv[94/160]\n",
      "Output data62.csv[95/160]\n",
      "Output data132.csv[96/160]\n",
      "Output data97.csv[97/160]\n",
      "Output data121.csv[98/160]\n",
      "Output data69.csv[99/160]\n",
      "Output data91.csv[100/160]\n",
      "Output data24.csv[101/160]\n",
      "Output data71.csv[102/160]\n",
      "Output data63.csv[103/160]\n",
      "Output data54.csv[104/160]\n",
      "Output data146.csv[105/160]\n",
      "Output data44.csv[106/160]\n",
      "Output data165.csv[107/160]\n",
      "Output data184.csv[108/160]\n",
      "Output data130.csv[109/160]\n",
      "Output data163.csv[110/160]\n",
      "Output data47.csv[111/160]\n",
      "Output data123.csv[112/160]\n",
      "Output data6.csv[113/160]\n",
      "Output data164.csv[114/160]\n",
      "Output data179.csv[115/160]\n",
      "Output data25.csv[116/160]\n",
      "Output data57.csv[117/160]\n",
      "Output data190.csv[118/160]\n",
      "Output data10.csv[119/160]\n",
      "Output data52.csv[120/160]\n",
      "Output data103.csv[121/160]\n",
      "Output data166.csv[122/160]\n",
      "Output data81.csv[123/160]\n",
      "Output data181.csv[124/160]\n",
      "Output data18.csv[125/160]\n",
      "Output data70.csv[126/160]\n",
      "Output data133.csv[127/160]\n",
      "Output data197.csv[128/160]\n",
      "Output data16.csv[129/160]\n",
      "Output data114.csv[130/160]\n",
      "Output data86.csv[131/160]\n",
      "Output data187.csv[132/160]\n",
      "Output data59.csv[133/160]\n",
      "Output data161.csv[134/160]\n",
      "Output data182.csv[135/160]\n",
      "Output data22.csv[136/160]\n",
      "Output data12.csv[137/160]\n",
      "Output data193.csv[138/160]\n",
      "Output data31.csv[139/160]\n",
      "Output data186.csv[140/160]\n",
      "Output data39.csv[141/160]\n",
      "Output data177.csv[142/160]\n",
      "Output data41.csv[143/160]\n",
      "Output data73.csv[144/160]\n",
      "Output data19.csv[145/160]\n",
      "Output data50.csv[146/160]\n",
      "Output data122.csv[147/160]\n",
      "Output data23.csv[148/160]\n",
      "Output data46.csv[149/160]\n",
      "Output data142.csv[150/160]\n",
      "Output data137.csv[151/160]\n",
      "Output data76.csv[152/160]\n",
      "Output data194.csv[153/160]\n",
      "Output data17.csv[154/160]\n",
      "Output data37.csv[155/160]\n",
      "Output data168.csv[156/160]\n",
      "Output data15.csv[157/160]\n",
      "Output data99.csv[158/160]\n",
      "Output data92.csv[159/160]\n",
      "Output data141.csv[160/160]\n",
      "Complete task\n"
     ]
    }
   ],
   "source": [
    "# import library\n",
    "from glob import glob\n",
    "import os\n",
    "from os.path import join\n",
    "import random\n",
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "fft_pattern = 3_2\n",
    "Path = './step2/output'+fft_pattern+'_csv/'\n",
    "# Path = './step2/output31_2_csv/'\n",
    "# get file list\n",
    "# files = glob(join(img_src, '*.csv'))\n",
    "test_file = np.loadtxt('./test_file_list.csv', delimiter=',',skiprows=1, dtype='object')\n",
    "train_file = np.loadtxt('./train_file_list.csv', delimiter=',',skiprows=1, dtype='object' )\n",
    "# # split data into train and test sets(8:2)\n",
    "# train_file, test_file = train_test_split(files, train_size=0.8)\n",
    "# df1 = pd.DataFrame(train_file)\n",
    "# df2 = pd.DataFrame(test_file)\n",
    "# df1.to_csv('./train_file_list.csv', index=None)\n",
    "# df2.to_csv('./test_file_list.csv', index=None)\n",
    "# apply SVM\n",
    "for num in range(len(train_file)):\n",
    "    df = pd.read_csv(Path+train_file[num])\n",
    "    clf = svm.SVC()\n",
    "    train_X,train_y = df.iloc[:,:-1].values,df.iloc[:,-1].values\n",
    "    clf.fit(train_X,train_y)\n",
    "    print('Fitting '+str(num+1)+ '/' + str(len(train_file)))\n",
    "# # output model\n",
    "print('Save model')\n",
    "joblib.dump(clf, './train'+fft_pattern+'.learn')\n",
    "load model\n",
    "print('Load model')\n",
    "# clf4 = joblib.load('./train31_2.learn')\n",
    "clf4 = joblib.load('./train'+fft_pattern+'.learn')\n",
    "# load test data\n",
    "savename = join('./','./evaluation3_3_2_train.xlsx')\n",
    "# savename = join('./','./evaluation31_31_2.xlsx')\n",
    "if os.path.exists(savename):\n",
    "    os.remove(savename)\n",
    "# ## implement test file ##\n",
    "for num in range(len(test_file)):\n",
    "    df = pd.read_csv(Path + test_file[num])\n",
    "    test_X,test_y = df.iloc[:,:-1].values,df.iloc[:,-1].values\n",
    "    # result\n",
    "    predicted_y = clf4.predict(test_X)\n",
    "    print('Output ' +str(test_file[num]) +'['+ str(num+1) + '/' + str(len(test_file))+']')\n",
    "    # evaluation(accuracy)\n",
    "    report = classification_report(test_y, predicted_y, output_dict=True)\n",
    "    sheetname = os.path.splitext(os.path.basename(test_file[num]))[0]\n",
    "    result = pd.DataFrame(report).transpose()\n",
    "    if os.path.exists(savename):\n",
    "        with pd.ExcelWriter(savename, engine=\"openpyxl\", mode=\"a\") as writer:\n",
    "            result.to_excel(writer, sheet_name=sheetname)\n",
    "    else:\n",
    "        with pd.ExcelWriter(savename, engine=\"openpyxl\") as writer:\n",
    "            result.to_excel(writer, sheet_name=sheetname)\n",
    "############################\n",
    "\n",
    "# ## implement train file ##\n",
    "# for num in range(len(train_file)):\n",
    "#     df = pd.read_csv(Path + train_file[num])\n",
    "#     train_X,train_y = df.iloc[:,:-1].values,df.iloc[:,-1].values\n",
    "#     # result\n",
    "#     predicted_y = clf4.predict(train_X)\n",
    "#     print('Output ' +str(train_file[num]) +'['+ str(num+1) + '/' + str(len(train_file))+']')\n",
    "#     # evaluation(accuracy)\n",
    "#     report = classification_report(train_y, predicted_y, output_dict=True)\n",
    "#     sheetname = os.path.splitext(os.path.basename(train_file[num]))[0]\n",
    "#     result = pd.DataFrame(report).transpose()\n",
    "#     if os.path.exists(savename):\n",
    "#         with pd.ExcelWriter(savename, engine=\"openpyxl\", mode=\"a\") as writer:\n",
    "#             result.to_excel(writer, sheet_name=sheetname)\n",
    "#     else:\n",
    "#         with pd.ExcelWriter(savename, engine=\"openpyxl\") as writer:\n",
    "#             result.to_excel(writer, sheet_name=sheetname)\n",
    "############################\n",
    "\n",
    "print('Complete task')\n",
    "#     df_r = pd.DataFrame(report).transpose()\n",
    "#     df_r[num].to_csv = ('./evaluation_5_5.csv')\n",
    "#     print(score)\n",
    "#     score = metrics.accuracy_score(test_y, predicted_y)\n",
    "#     print(\"Score:\", score)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-delhi",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # import library\n",
    "# from glob import glob\n",
    "# import os\n",
    "# from os.path import join\n",
    "# import random\n",
    "# from sklearn import svm\n",
    "# from sklearn import datasets\n",
    "# import joblib\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn import metrics\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import openpyxl\n",
    "# import pprint\n",
    "# # load model\n",
    "# clf4 = joblib.load('./train.learn')\n",
    "# test_file = np.loadtxt('./test_file_list.csv', delimiter=',',skiprows=1, dtype='object')\n",
    "# # Predict test data\n",
    "# savename = join('./','./evaluation5_5.xlsx')\n",
    "# if os.path.exists(savename):\n",
    "#     os.remove(savename)\n",
    "# for num in range(len(test_file)):\n",
    "#     df = pd.read_csv(test_file[num])\n",
    "#     test_X,test_y = df.iloc[:,:-1].values,df.iloc[:,-1].values\n",
    "#     # result\n",
    "#     predicted_y = clf4.predict(test_X)\n",
    "#     # evaluation(accuracy)\n",
    "#     report = classification_report(test_y, predicted_y, output_dict=True)\n",
    "#     sheetname = os.path.splitext(os.path.basename(test_file[num]))[0]\n",
    "# #     sheetname = 'result'+ str(num)\n",
    "#     result = pd.DataFrame(report).transpose()\n",
    "#     if os.path.exists(savename):\n",
    "#         with pd.ExcelWriter(savename, engine=\"openpyxl\", mode=\"a\") as writer:\n",
    "#             result.to_excel(writer, sheet_name=sheetname)\n",
    "#     else:\n",
    "#         with pd.ExcelWriter(savename, engine=\"openpyxl\") as writer:\n",
    "#             result.to_excel(writer, sheet_name=sheetname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "geological-relaxation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 372.800025940 [sec]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/jh372/CS5014/python/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/cs/home/jh372/CS5014/python/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/cs/home/jh372/CS5014/python/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "def unit_test(filename):\n",
    "    tic()\n",
    "    df = pd.read_csv(filename) #elapsed time: 151.782285452 [sec]\n",
    "    X,y = df.iloc[:,:-1].values,df.iloc[:,-1].values\n",
    "    pre_y = clf4.predict(X)\n",
    "#     report = classification_report(y, pre_y, output_dict=True)\n",
    "#     result = pd.DataFrame(report).transpose()\n",
    "#     result.to_csv('./evaluation_5_5_test.csv')\n",
    "    toc()\n",
    "\n",
    "unit_test(test_file[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50df605",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.loadtxt('./test_file_list.csv', delimiter=',',skiprows=1, dtype='object')\n",
    "train = np.loadtxt('./train_file_list.csv', delimiter=',',skiprows=1, skipcolumns = 1, dtype='object' )\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "distinguished-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for counting time\n",
    "import time\n",
    "\n",
    "def tic():\n",
    "    #require  to import time\n",
    "    global start_time_tictoc\n",
    "    start_time_tictoc = time.time()\n",
    "\n",
    "\n",
    "def toc(tag=\"elapsed time\"):\n",
    "    if \"start_time_tictoc\" in globals():\n",
    "        print(\"{}: {:.9f} [sec]\".format(tag, time.time() - start_time_tictoc))\n",
    "    else:\n",
    "        print(\"tic has not been called\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-blink",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
