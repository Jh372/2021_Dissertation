{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "turned-extra",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1/160\n",
      "Fitting 2/160\n",
      "Fitting 3/160\n",
      "Fitting 4/160\n",
      "Fitting 5/160\n",
      "Fitting 6/160\n",
      "Fitting 7/160\n",
      "Fitting 8/160\n",
      "Fitting 9/160\n",
      "Fitting 10/160\n",
      "Fitting 11/160\n",
      "Fitting 12/160\n",
      "Fitting 13/160\n",
      "Fitting 14/160\n",
      "Fitting 15/160\n",
      "Fitting 16/160\n",
      "Fitting 17/160\n",
      "Fitting 18/160\n",
      "Fitting 19/160\n",
      "Fitting 20/160\n",
      "Fitting 21/160\n",
      "Fitting 22/160\n",
      "Fitting 23/160\n",
      "Fitting 24/160\n",
      "Fitting 25/160\n",
      "Fitting 26/160\n",
      "Fitting 27/160\n",
      "Fitting 28/160\n",
      "Fitting 29/160\n",
      "Fitting 30/160\n",
      "Fitting 31/160\n",
      "Fitting 32/160\n",
      "Fitting 33/160\n",
      "Fitting 34/160\n",
      "Fitting 35/160\n",
      "Fitting 36/160\n",
      "Fitting 37/160\n",
      "Fitting 38/160\n",
      "Fitting 39/160\n",
      "Fitting 40/160\n",
      "Fitting 41/160\n",
      "Fitting 42/160\n",
      "Fitting 43/160\n",
      "Fitting 44/160\n",
      "Fitting 45/160\n",
      "Fitting 46/160\n",
      "Fitting 47/160\n",
      "Fitting 48/160\n",
      "Fitting 49/160\n",
      "Fitting 50/160\n",
      "Fitting 51/160\n",
      "Fitting 52/160\n",
      "Fitting 53/160\n",
      "Fitting 54/160\n",
      "Fitting 55/160\n",
      "Fitting 56/160\n",
      "Fitting 57/160\n",
      "Fitting 58/160\n",
      "Fitting 59/160\n",
      "Fitting 60/160\n",
      "Fitting 61/160\n",
      "Fitting 62/160\n",
      "Fitting 63/160\n",
      "Fitting 64/160\n",
      "Fitting 65/160\n",
      "Fitting 66/160\n",
      "Fitting 67/160\n",
      "Fitting 68/160\n",
      "Fitting 69/160\n",
      "Fitting 70/160\n",
      "Fitting 71/160\n",
      "Fitting 72/160\n",
      "Fitting 73/160\n",
      "Fitting 74/160\n",
      "Fitting 75/160\n",
      "Fitting 76/160\n",
      "Fitting 77/160\n",
      "Fitting 78/160\n",
      "Fitting 79/160\n",
      "Fitting 80/160\n",
      "Fitting 81/160\n",
      "Fitting 82/160\n",
      "Fitting 83/160\n",
      "Fitting 84/160\n",
      "Fitting 85/160\n",
      "Fitting 86/160\n",
      "Fitting 87/160\n",
      "Fitting 88/160\n",
      "Fitting 89/160\n",
      "Fitting 90/160\n",
      "Fitting 91/160\n",
      "Fitting 92/160\n",
      "Fitting 93/160\n",
      "Fitting 94/160\n",
      "Fitting 95/160\n",
      "Fitting 96/160\n",
      "Fitting 97/160\n",
      "Fitting 98/160\n",
      "Fitting 99/160\n",
      "Fitting 100/160\n",
      "Fitting 101/160\n",
      "Fitting 102/160\n",
      "Fitting 103/160\n",
      "Fitting 104/160\n",
      "Fitting 105/160\n",
      "Fitting 106/160\n",
      "Fitting 107/160\n",
      "Fitting 108/160\n",
      "Fitting 109/160\n",
      "Fitting 110/160\n",
      "Fitting 111/160\n",
      "Fitting 112/160\n",
      "Fitting 113/160\n",
      "Fitting 114/160\n",
      "Fitting 115/160\n",
      "Fitting 116/160\n",
      "Fitting 117/160\n",
      "Fitting 118/160\n",
      "Fitting 119/160\n",
      "Fitting 120/160\n",
      "Fitting 121/160\n",
      "Fitting 122/160\n",
      "Fitting 123/160\n",
      "Fitting 124/160\n",
      "Fitting 125/160\n",
      "Fitting 126/160\n",
      "Fitting 127/160\n",
      "Fitting 128/160\n",
      "Fitting 129/160\n",
      "Fitting 130/160\n",
      "Fitting 131/160\n",
      "Fitting 132/160\n",
      "Fitting 133/160\n",
      "Fitting 134/160\n",
      "Fitting 135/160\n",
      "Fitting 136/160\n",
      "Fitting 137/160\n",
      "Fitting 138/160\n",
      "Fitting 139/160\n",
      "Fitting 140/160\n",
      "Fitting 141/160\n",
      "Fitting 142/160\n",
      "Fitting 143/160\n",
      "Fitting 144/160\n",
      "Fitting 145/160\n",
      "Fitting 146/160\n",
      "Fitting 147/160\n",
      "Fitting 148/160\n",
      "Fitting 149/160\n",
      "Fitting 150/160\n",
      "Fitting 151/160\n",
      "Fitting 152/160\n",
      "Fitting 153/160\n",
      "Fitting 154/160\n",
      "Fitting 155/160\n",
      "Fitting 156/160\n",
      "Fitting 157/160\n",
      "Fitting 158/160\n",
      "Fitting 159/160\n",
      "Fitting 160/160\n",
      "Save model\n",
      "Load model\n",
      "Output data68.csv[1/40]\n",
      "Output data40.csv[2/40]\n",
      "Output data79.csv[3/40]\n",
      "Output data116.csv[4/40]\n",
      "Output data113.csv[5/40]\n",
      "Output data13.csv[6/40]\n",
      "Output data126.csv[7/40]\n",
      "Output data42.csv[8/40]\n",
      "Output data35.csv[9/40]\n",
      "Output data43.csv[10/40]\n",
      "Output data58.csv[11/40]\n",
      "Output data136.csv[12/40]\n",
      "Output data129.csv[13/40]\n",
      "Output data26.csv[14/40]\n",
      "Output data38.csv[15/40]\n",
      "Output data30.csv[16/40]\n",
      "Output data188.csv[17/40]\n",
      "Output data61.csv[18/40]\n",
      "Output data21.csv[19/40]\n",
      "Output data198.csv[20/40]\n",
      "Output data134.csv[21/40]\n",
      "Output data60.csv[22/40]\n",
      "Output data36.csv[23/40]\n",
      "Output data34.csv[24/40]\n",
      "Output data180.csv[25/40]\n",
      "Output data125.csv[26/40]\n",
      "Output data135.csv[27/40]\n",
      "Output data2.csv[28/40]\n",
      "Output data67.csv[29/40]\n",
      "Output data56.csv[30/40]\n",
      "Output data29.csv[31/40]\n",
      "Output data51.csv[32/40]\n",
      "Output data100.csv[33/40]\n",
      "Output data120.csv[34/40]\n",
      "Output data3.csv[35/40]\n",
      "Output data124.csv[36/40]\n",
      "Output data75.csv[37/40]\n",
      "Output data98.csv[38/40]\n",
      "Output data65.csv[39/40]\n",
      "Output data48.csv[40/40]\n",
      "Complete task\n"
     ]
    }
   ],
   "source": [
    "# import library\n",
    "from glob import glob\n",
    "import os\n",
    "from os.path import join\n",
    "import random\n",
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "Path = './step2/output6_22_new_csv/'\n",
    "# Path = './step2/output31_2_csv/'\n",
    "# get file list\n",
    "# files = glob(join(img_src, '*.csv'))\n",
    "test_file = np.loadtxt('./test_file_list.csv', delimiter=',',skiprows=1, dtype='object')\n",
    "train_file = np.loadtxt('./train_file_list.csv', delimiter=',',skiprows=1, dtype='object' )\n",
    "# # split data into train and test sets(8:2)\n",
    "# train_file, test_file = train_test_split(files, train_size=0.8)\n",
    "# df1 = pd.DataFrame(train_file)\n",
    "# df2 = pd.DataFrame(test_file)\n",
    "# df1.to_csv('./train_file_list.csv', index=None)\n",
    "# df2.to_csv('./test_file_list.csv', index=None)\n",
    "# apply SVM\n",
    "for num in range(len(train_file)):\n",
    "    df = pd.read_csv(Path+train_file[num])\n",
    "    clf = svm.SVC()\n",
    "#     train_X1,train_X2,train_y = df.iloc[:,:-2],df.iloc[:,-2],df.iloc[:,-1].values # X1,X2:dataframe y:array\n",
    "#     train_X2 = pd.get_dummies(train_X2,sparse=True) # one-hot encoding regarding edge label\n",
    "#     train_X = train_X1.join(train_X2).values # X:array\n",
    "    train_X,train_y = df.iloc[:,:-1].values,df.iloc[:,-1].values # before adding edge label\n",
    "    clf.fit(train_X,train_y)\n",
    "    print('Fitting '+str(num+1)+ '/' + str(len(train_file)))\n",
    "# # output model\n",
    "print('Save model')\n",
    "joblib.dump(clf, './train6_22.learn')\n",
    "# load model\n",
    "print('Load model')\n",
    "# clf4 = joblib.load('./train31_2.learn')\n",
    "clf4 = joblib.load('./train6_22.learn')\n",
    "# load test data\n",
    "# savename = join('./','./evaluation3_3_2_train.xlsx')\n",
    "savename = join('./','./evaluation6_6_22.xlsx')\n",
    "if os.path.exists(savename):\n",
    "    os.remove(savename)\n",
    "\n",
    "### implement test file ###\n",
    "for num in range(len(test_file)):\n",
    "    df = pd.read_csv(Path + test_file[num])\n",
    "#     test_X1,test_X2,test_y = df.iloc[:,:-2],df.iloc[:,-2],df.iloc[:,-1].values # X1,X2:dataframe y:array\n",
    "#     test_X2 = pd.get_dummies(test_X2,sparse=True)\n",
    "#     test_X = test_X1.join(test_X2).values # X:array\n",
    "    test_X,test_y = df.iloc[:,:-1].values,df.iloc[:,-1].values #before introducing edge label\n",
    "    # result\n",
    "    predicted_y = clf4.predict(test_X)\n",
    "    print('Output ' +str(test_file[num]) +'['+ str(num+1) + '/' + str(len(test_file))+']')\n",
    "    # evaluation(accuracy)\n",
    "    report = classification_report(test_y, predicted_y, output_dict=True)\n",
    "    sheetname = os.path.splitext(os.path.basename(test_file[num]))[0]\n",
    "    result = pd.DataFrame(report).transpose()\n",
    "    if os.path.exists(savename):\n",
    "        with pd.ExcelWriter(savename, engine=\"openpyxl\", mode=\"a\") as writer:\n",
    "            result.to_excel(writer, sheet_name=sheetname)\n",
    "    else:\n",
    "        with pd.ExcelWriter(savename, engine=\"openpyxl\") as writer:\n",
    "            result.to_excel(writer, sheet_name=sheetname)\n",
    "############################\n",
    "\n",
    "# ## implement train file ##\n",
    "# for num in range(len(train_file)):\n",
    "#     df = pd.read_csv(Path + train_file[num])\n",
    "#     train_X,train_y = df.iloc[:,:-1].values,df.iloc[:,-1].values\n",
    "#     # result\n",
    "#     predicted_y = clf4.predict(train_X)\n",
    "#     print('Output ' +str(train_file[num]) +'['+ str(num+1) + '/' + str(len(train_file))+']')\n",
    "#     # evaluation(accuracy)\n",
    "#     report = classification_report(train_y, predicted_y, output_dict=True)\n",
    "#     sheetname = os.path.splitext(os.path.basename(train_file[num]))[0]\n",
    "#     result = pd.DataFrame(report).transpose()\n",
    "#     if os.path.exists(savename):\n",
    "#         with pd.ExcelWriter(savename, engine=\"openpyxl\", mode=\"a\") as writer:\n",
    "#             result.to_excel(writer, sheet_name=sheetname)\n",
    "#     else:\n",
    "#         with pd.ExcelWriter(savename, engine=\"openpyxl\") as writer:\n",
    "#             result.to_excel(writer, sheet_name=sheetname)\n",
    "############################\n",
    "\n",
    "print('Complete task')\n",
    "#     df_r = pd.DataFrame(report).transpose()\n",
    "#     df_r[num].to_csv = ('./evaluation_5_5.csv')\n",
    "#     print(score)\n",
    "#     score = metrics.accuracy_score(test_y, predicted_y)\n",
    "#     print(\"Score:\", score)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "numeric-delhi",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # import library\n",
    "# from glob import glob\n",
    "# import os\n",
    "# from os.path import join\n",
    "# import random\n",
    "# from sklearn import svm\n",
    "# from sklearn import datasets\n",
    "# import joblib\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn import metrics\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import openpyxl\n",
    "# import pprint\n",
    "# # load model\n",
    "# clf4 = joblib.load('./train.learn')\n",
    "# test_file = np.loadtxt('./test_file_list.csv', delimiter=',',skiprows=1, dtype='object')\n",
    "# # Predict test data\n",
    "# savename = join('./','./evaluation5_5.xlsx')\n",
    "# if os.path.exists(savename):\n",
    "#     os.remove(savename)\n",
    "# for num in range(len(test_file)):\n",
    "#     df = pd.read_csv(test_file[num])\n",
    "#     test_X,test_y = df.iloc[:,:-1].values,df.iloc[:,-1].values\n",
    "#     # result\n",
    "#     predicted_y = clf4.predict(test_X)\n",
    "#     # evaluation(accuracy)\n",
    "#     report = classification_report(test_y, predicted_y, output_dict=True)\n",
    "#     sheetname = os.path.splitext(os.path.basename(test_file[num]))[0]\n",
    "# #     sheetname = 'result'+ str(num)\n",
    "#     result = pd.DataFrame(report).transpose()\n",
    "#     if os.path.exists(savename):\n",
    "#         with pd.ExcelWriter(savename, engine=\"openpyxl\", mode=\"a\") as writer:\n",
    "#             result.to_excel(writer, sheet_name=sheetname)\n",
    "#     else:\n",
    "#         with pd.ExcelWriter(savename, engine=\"openpyxl\") as writer:\n",
    "#             result.to_excel(writer, sheet_name=sheetname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "geological-relaxation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 0.093665600 [sec]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "Path = './step2/output5_2_ed_csv/'\n",
    "def unit_test(filename):\n",
    "    tic()\n",
    "    df = pd.read_csv(filename) #elapsed time: 151.782285452 [sec]\n",
    "#     X1,y = df.iloc[:,:-2].values,df.iloc[:,-1].values\n",
    "    X1,y = df.iloc[:,:-2],df.iloc[:,-1].values\n",
    "#     pre_y = clf4.predict(X)\n",
    "#     report = classification_report(y, pre_y, output_dict=True)\n",
    "#     result = pd.DataFrame(report).transpose()\n",
    "#     result.to_csv('./evaluation_5_5_test.csv')\n",
    "    toc()\n",
    "    return X1, y,df\n",
    "\n",
    "X1, y,df =unit_test(Path+test_file[0])\n",
    "df = df.loc[:,'position'].values\n",
    "df = pd.get_dummies(df,sparse=True)\n",
    "# df = df.values\n",
    "X = X1\n",
    "# X.append(df)\n",
    "df\n",
    "y\n",
    "# X1.join(df).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50df605",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.loadtxt('./test_file_list.csv', delimiter=',',skiprows=1, dtype='object')\n",
    "train = np.loadtxt('./train_file_list.csv', delimiter=',',skiprows=1, skipcolumns = 1, dtype='object' )\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "distinguished-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for counting time\n",
    "import time\n",
    "\n",
    "def tic():\n",
    "    #require  to import time\n",
    "    global start_time_tictoc\n",
    "    start_time_tictoc = time.time()\n",
    "\n",
    "\n",
    "def toc(tag=\"elapsed time\"):\n",
    "    if \"start_time_tictoc\" in globals():\n",
    "        print(\"{}: {:.9f} [sec]\".format(tag, time.time() - start_time_tictoc))\n",
    "    else:\n",
    "        print(\"tic has not been called\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-blink",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
