{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42bca9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "from glob import glob\n",
    "import os\n",
    "from os.path import join\n",
    "import random\n",
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import openpyxl\n",
    "import cv2\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2a8e119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(split_ratio, img_src):\n",
    "    # get file list\n",
    "    files = glob(join(img_src, '*.csv'))\n",
    "    # split data into train and test sets(8:2)\n",
    "    train_file, test_file = train_test_split(files, train_size=split_ratio)\n",
    "    # Extract file name\n",
    "    for f in range(len(train_file)):\n",
    "        train_file[f] = os.path.split(train_file[f])[1]\n",
    "    for f in range(len(test_file)):\n",
    "        test_file[f] = os.path.split(test_file[f])[1]\n",
    "    return train_file, test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcab8a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already exits files\n"
     ]
    }
   ],
   "source": [
    "# check file list\n",
    "ck_train = join('./','./train_file_list.csv')\n",
    "ck_test = join('./','./test_file_list.csv')\n",
    "if (os.path.exists(ck_train)) and (os.path.exists(ck_test)):\n",
    "    print('already exits files')\n",
    "else:\n",
    "    os.remove(ck_train)\n",
    "    os.remove(ck_test)\n",
    "    img_src = './step2/output31_csv' #select name folder after creating 200 data to separate training and test data\n",
    "    train_file, test_file = split(0.8,img_src)\n",
    "    df1 = pd.DataFrame(train_file)\n",
    "    df2 = pd.DataFrame(test_file)\n",
    "    # Save CSVfiles\n",
    "    df1.to_csv('./train_file_list.csv', index=None)\n",
    "    df2.to_csv('./test_file_list.csv', index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "turned-extra",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model\n",
      "Output data68.csv[1/40]\n",
      "Now create img file[1/40]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_238473/3692749878.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;31m#before introducing edge label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mpredicted_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Output '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'['\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m']'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# evaluation(accuracy)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/python/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/python/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_dense_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/python/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0msvm_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLIBSVM_IMPL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m         return libsvm.predict(\n\u001b[0m\u001b[1;32m    362\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_vectors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_support\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dual_coef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_intercept_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# foldername: output5_csv, output21_csv, output31_csv, output6_3_csv, output32_16_csv, output5_de_csv \n",
    "foldername = 'output31_csv/'\n",
    "Path = './step2/'+ foldername\n",
    "# get file list\n",
    "test_file = np.loadtxt('./test_file_list.csv', delimiter=',',skiprows=1, dtype='object')\n",
    "train_file = np.loadtxt('./train_file_list.csv', delimiter=',',skiprows=1, dtype='object' )\n",
    "\n",
    "# #### apply Support Vector Machine #### parameters:default\n",
    "\n",
    "# clf = svm.SVC() # initialisation\n",
    "# for num in range(len(train_file)):\n",
    "#     df = pd.read_csv(Path+train_file[num])\n",
    "# #### for adding labels of pixels on the edge ####\n",
    "# #     train_X1,train_X2,train_y = df.iloc[:,:-2],df.iloc[:,-2],df.iloc[:,-1].values # X1,X2:dataframe y:array\n",
    "# #     train_X2 = pd.get_dummies(train_X2,sparse=True) # one-hot encoding regarding edge label\n",
    "# #     train_X = train_X1.join(train_X2).values # X:array\n",
    "# #################################################\n",
    "#     train_X,train_y = df.iloc[:,:-1].values,df.iloc[:,-1].values # before adding edge label\n",
    "#     clf.fit(train_X,train_y)\n",
    "#     print('Fitting '+str(num+1)+ '/' + str(len(train_file))) # learn 160 training sets\n",
    "\n",
    "# # output model\n",
    "# print('Save model')\n",
    "# modelname: ./train5.learn, ./train21.learn, ./train31.learn, ./train6_3.learn,./train32_16.learn, ./train5_de.learn \n",
    "modelname = './train31.learn'\n",
    "# joblib.dump(clf, modelname)\n",
    "\n",
    "#### Create classification report and visualised images ####\n",
    "# savedir: ./pre_img5X5, ./pre_img21X21, ./pre_img31X31, ./pre_img6X6_3, ./pre_img32X32_16, ./pre_img5X5_de\n",
    "savedir = './pre_img31X31'\n",
    "os.makedirs(savedir+'/SVC_vis',exist_ok=True) # create directory for predicted imgs \n",
    "os.makedirs(savedir+'/SVC',exist_ok=True) # create directory for unshaded txt based on predicted label\n",
    "os.makedirs(savedir+'/shading',exist_ok=True) # create directory for shading txt\n",
    "\n",
    "# load model\n",
    "print('Load model')\n",
    "clf4 = joblib.load(modelname)\n",
    "# load test data\n",
    "#savename: ./evaluation5.xlsx, ./evaluation21.xlsx, ./evaluation31.xlsx, ./evaluation6_3.xlsx, ./evaluation32_16.xlsx,\n",
    "#          ./evaluation5_de.xlsx\n",
    "savename = join('./','./evaluation31.xlsx')\n",
    "if os.path.exists(savename):\n",
    "    os.remove(savename)\n",
    "\n",
    "### implement test file ###\n",
    "for num in range(len(test_file)):\n",
    "    df = pd.read_csv(Path + test_file[num])\n",
    "    height,width = df.iloc[-1,0],df.iloc[-1,1]\n",
    "#### for adding labels of pixels on the edge ####\n",
    "#     test_X1,test_X2,test_y = df.iloc[:,:-2],df.iloc[:,-2],df.iloc[:,-1].values # X1,X2:dataframe y:array\n",
    "#     test_X2 = pd.get_dummies(test_X2,sparse=True)\n",
    "#     test_X = test_X1.join(test_X2).values # X:array\n",
    "#################################################\n",
    "    test_X,test_y = df.iloc[:,:-1].values,df.iloc[:,-1].values #before introducing edge label\n",
    "    # result\n",
    "    predicted_y = clf4.predict(test_X)\n",
    "    print('Output ' +str(test_file[num]) +'['+ str(num+1) + '/' + str(len(test_file))+']')\n",
    "    # evaluation(accuracy)\n",
    "    report = classification_report(test_y, predicted_y, output_dict=True)\n",
    "    sheetname = os.path.splitext(os.path.basename(test_file[num]))[0]\n",
    "    result = pd.DataFrame(report).transpose()\n",
    "    if os.path.exists(savename):\n",
    "        with pd.ExcelWriter(savename, engine=\"openpyxl\", mode=\"a\") as writer:\n",
    "            result.to_excel(writer, sheet_name=sheetname)\n",
    "    else:\n",
    "        with pd.ExcelWriter(savename, engine=\"openpyxl\") as writer:\n",
    "            result.to_excel(writer, sheet_name=sheetname)\n",
    "### initialisation ###\n",
    "    predicted_y = predicted_y.reshape([int(height+1),int(width+1)])\n",
    "    test_y = test_y.reshape([int(height+1),int(width+1)])\n",
    "#     train_y = train_y.reshape([int(height+1),int(width+1)]) # for sending predicted shading texts to a partner\n",
    "    pre_vis =  copy.copy(predicted_y)\n",
    "    pre_vis_3 = cv2.merge([pre_vis,pre_vis,pre_vis])\n",
    "    pre_label = np.zeros_like(predicted_y, dtype=np.uint8)\n",
    "    pre_shading_label = np.zeros_like(predicted_y, dtype=np.uint8)\n",
    "    \n",
    "### modifying label to restore the symbol texts ###\n",
    "## output predicted image (Red:part of shading, Black: part of text)\n",
    "# Note: the format is BGR when using Open CV\n",
    "### restore unshaded txt and visualised images###\n",
    "    for i in range(int(height)):\n",
    "        for j in range(int(width)):\n",
    "#             if predicted_y[i,j] == 1 and train_y[i,j] ==1:\n",
    "            if predicted_y[i,j] == 1 and test_y[i,j] ==1:\n",
    "                pre_label[i,j] = 255 #1\n",
    "                pre_vis_3[i,j] = np.array([0,0,255]) # Color code #FF0000(Red)\n",
    "#             elif predicted_y[i,j] == 1 and train_y[i,j] ==2:\n",
    "            elif predicted_y[i,j] == 1 and test_y[i,j] ==2:\n",
    "                pre_label[i,j] = 255\n",
    "                pre_vis_3[i,j] = np.array([255,255,0]) # Color code #00FFFF(Cyan)\n",
    "#             elif predicted_y[i,j] == 2 and train_y[i,j]==2:\n",
    "            elif predicted_y[i,j] == 2 and test_y[i,j]==2:\n",
    "                pre_label[i,j] = 0 #1\n",
    "                pre_vis_3[i,j] = np.array([0,0,0]) # Color code #000000(Black)\n",
    "#             elif predicted_y[i,j] ==2 and train_y[i,j] == 1:\n",
    "            elif predicted_y[i,j] ==2 and test_y[i,j] == 1:\n",
    "                pre_label[i,j] = 0 #1\n",
    "                pre_vis_3[i,j] = np.array([0,140,255]) # Color code #FF8C00(DarkOrange)                \n",
    "            else:\n",
    "                pre_label[i,j] = 255 #1\n",
    "                pre_vis_3[i,j] = np.array([255,255,255]) # Color code #FFFFFF(White)\n",
    "####################################################\n",
    "\n",
    "### modifying label to restore the only shading texts ###\n",
    "    for k in range(int(height)):\n",
    "        for l in range(int(width)):\n",
    "            if predicted_y[k,l] != 1:\n",
    "                pre_shading_label[k,l] = 255\n",
    "            else:\n",
    "                pre_shading_label[k,l] = 0\n",
    "#########################################################\n",
    "    pre_label = pre_label.astype(int)# change type (float -> int) \n",
    "    pre_shading_label = pre_shading_label.astype(int)# change type (float -> int)\n",
    "    \n",
    "### output img SVC / extract only shading ### \n",
    "#     print(pre_vis_3) # for check output\n",
    "    cv2.imwrite(savedir+'/SVC/'+sheetname + 'SVC.png',pre_label) #output img using SVC\n",
    "    cv2.imwrite(savedir+'/SVC_vis/'+sheetname + 'SVC_vis.png',pre_vis_3) #output img using SVC visualisation\n",
    "    cv2.imwrite(savedir+'/shading/' +sheetname +'shading.png', pre_shading_label) #output shading img\n",
    "    print('Now create img file'+'['+str(num+1)+'/'+str(len(test_file))+']') # testfile comment\n",
    "#     print('Now create img file'+'['+str(num+1)+'/'+str(len(train_file))+']') # trainfile comment    \n",
    "#############################################\n",
    "\n",
    "# ## implement train file for checking overfitting ##\n",
    "# for num in range(len(train_file)):\n",
    "#     df = pd.read_csv(Path + train_file[num])\n",
    "#     train_X,train_y = df.iloc[:,:-1].values,df.iloc[:,-1].values\n",
    "#     # result\n",
    "#     predicted_y = clf4.predict(train_X)\n",
    "#     print('Output ' +str(train_file[num]) +'['+ str(num+1) + '/' + str(len(train_file))+']')\n",
    "#     # evaluation(accuracy)\n",
    "#     report = classification_report(train_y, predicted_y, output_dict=True)\n",
    "#     sheetname = os.path.splitext(os.path.basename(train_file[num]))[0]\n",
    "#     result = pd.DataFrame(report).transpose()\n",
    "#     if os.path.exists(savename):\n",
    "#         with pd.ExcelWriter(savename, engine=\"openpyxl\", mode=\"a\") as writer:\n",
    "#             result.to_excel(writer, sheet_name=sheetname)\n",
    "#     else:\n",
    "#         with pd.ExcelWriter(savename, engine=\"openpyxl\") as writer:\n",
    "#             result.to_excel(writer, sheet_name=sheetname)\n",
    "#####################################################\n",
    "\n",
    "print('Complete task')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-blink",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
