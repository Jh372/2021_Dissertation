{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a95383eb",
   "metadata": {},
   "source": [
    "Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42bca9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "from glob import glob\n",
    "import os\n",
    "from os.path import join\n",
    "import random\n",
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import openpyxl\n",
    "import cv2\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2a8e119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(split_ratio, img_src):\n",
    "    # get file list\n",
    "    files = glob(join(img_src, '*.csv'))\n",
    "    # split data into train and test sets(8:2)\n",
    "    train_file, test_file = train_test_split(files, train_size=split_ratio)\n",
    "    # Extract file name\n",
    "    for f in range(len(train_file)):\n",
    "        train_file[f] = os.path.split(train_file[f])[1]\n",
    "    for f in range(len(test_file)):\n",
    "        test_file[f] = os.path.split(test_file[f])[1]\n",
    "    return train_file, test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcab8a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFFTgrid = 5\n",
    "# inputFFTgrid = 21\n",
    "# inputFFTgrid = 31_2\n",
    "\n",
    "# check file list\n",
    "ck_train = join('./','./train_file_list.csv')\n",
    "ck_test = join('./','./test_file_list.csv')\n",
    "if (os.path.exists(ck_train)) and (os.path.exists(ck_test)):\n",
    "    print('already exits files')\n",
    "else:\n",
    "    os.remove(ck_train)\n",
    "    os.remove(ck_test)\n",
    "    img_src = './step2/output31_csv' #select name folder after creating 200 data to separate training and test data\n",
    "    train_file, test_file = split(0.8,img_src)\n",
    "    df1 = pd.DataFrame(train_file)\n",
    "    df2 = pd.DataFrame(test_file)\n",
    "    # Save CSVfiles\n",
    "    df1.to_csv('./train_file_list.csv', index=None)\n",
    "    df2.to_csv('./test_file_list.csv', index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54750c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# foldername: output5_csv, output21_csv, output31_csv, output6_3_csv, output32_16_csv, output5_de_csv \n",
    "foldername = 'output31_csv/'\n",
    "Path = './step2/'+ foldername\n",
    "# get file list\n",
    "test_file = np.loadtxt('./test_file_list.csv', delimiter=',',skiprows=1, dtype='object')\n",
    "train_file = np.loadtxt('./train_file_list.csv', delimiter=',',skiprows=1, dtype='object' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358d6d3f",
   "metadata": {},
   "source": [
    "Apply Support Vector Machine (SVM), Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-extra",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #### apply Support Vector Machine #### parameters:default\n",
    "\n",
    "clf = svm.SVC() # initialisation\n",
    "for num in range(len(train_file)):\n",
    "    df = pd.read_csv(Path+train_file[num])\n",
    "#### for adding labels of pixels on the edge ####\n",
    "#     train_X1,train_X2,train_y = df.iloc[:,:-2],df.iloc[:,-2],df.iloc[:,-1].values # X1,X2:dataframe y:array\n",
    "#     train_X2 = pd.get_dummies(train_X2,sparse=True) # one-hot encoding regarding edge label\n",
    "#     train_X = train_X1.join(train_X2).values # X:array\n",
    "#################################################\n",
    "    train_X,train_y = df.iloc[:,:-1].values,df.iloc[:,-1].values # before adding edge label\n",
    "    clf.fit(train_X,train_y)\n",
    "    print('Fitting '+str(num+1)+ '/' + str(len(train_file))) # learn 160 training sets\n",
    "\n",
    "# output model\n",
    "print('Save model')\n",
    "# modelname: ./train5.learn, ./train21.learn, ./train31.learn, ./train6_3.learn,./train32_16.learn, ./train5_de.learn \n",
    "modelname = './train31.learn'\n",
    "joblib.dump(clf, modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06517194",
   "metadata": {},
   "source": [
    "Create classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378f94e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Create classification report ####\n",
    "# savedir: ./pre_img5X5, ./pre_img21X21, ./pre_img31X31, ./pre_img6X6_3, ./pre_img32X32_16, ./pre_img5X5_de\n",
    "savedir = './pre_img31X31'\n",
    "os.makedirs(savedir+'/SVC_vis',exist_ok=True) # create directory for predicted imgs \n",
    "os.makedirs(savedir+'/SVC',exist_ok=True) # create directory for unshaded txt based on predicted label\n",
    "os.makedirs(savedir+'/shading',exist_ok=True) # create directory for shading txt\n",
    "\n",
    "# load model\n",
    "print('Load model')\n",
    "clf4 = joblib.load(modelname)\n",
    "# load test data\n",
    "#savename: ./evaluation5.xlsx, ./evaluation21.xlsx, ./evaluation31.xlsx, ./evaluation6_3.xlsx, ./evaluation32_16.xlsx,\n",
    "#          ./evaluation5_de.xlsx\n",
    "savename = join('./','./evaluation31.xlsx')\n",
    "if os.path.exists(savename):\n",
    "    os.remove(savename)\n",
    "\n",
    "### implement test file ###\n",
    "for num in range(len(test_file)):\n",
    "    df = pd.read_csv(Path + test_file[num])\n",
    "    height,width = df.iloc[-1,0],df.iloc[-1,1]\n",
    "#### for adding labels of pixels on the edge ####\n",
    "#     test_X1,test_X2,test_y = df.iloc[:,:-2],df.iloc[:,-2],df.iloc[:,-1].values # X1,X2:dataframe y:array\n",
    "#     test_X2 = pd.get_dummies(test_X2,sparse=True)\n",
    "#     test_X = test_X1.join(test_X2).values # X:array\n",
    "#################################################\n",
    "    test_X,test_y = df.iloc[:,:-1].values,df.iloc[:,-1].values #before introducing edge label\n",
    "    # result\n",
    "    predicted_y = clf4.predict(test_X)\n",
    "    print('Output ' +str(test_file[num]) +'['+ str(num+1) + '/' + str(len(test_file))+']')\n",
    "    # evaluation(accuracy)\n",
    "    report = classification_report(test_y, predicted_y, output_dict=True)\n",
    "    sheetname = os.path.splitext(os.path.basename(test_file[num]))[0]\n",
    "    result = pd.DataFrame(report).transpose()\n",
    "    if os.path.exists(savename):\n",
    "        with pd.ExcelWriter(savename, engine=\"openpyxl\", mode=\"a\") as writer:\n",
    "            result.to_excel(writer, sheet_name=sheetname)\n",
    "    else:\n",
    "        with pd.ExcelWriter(savename, engine=\"openpyxl\") as writer:\n",
    "            result.to_excel(writer, sheet_name=sheetname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3626f69c",
   "metadata": {},
   "source": [
    "Visualised images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-blink",
   "metadata": {},
   "outputs": [],
   "source": [
    " ### visualised images ###\n",
    " ### initialisation ###\n",
    "    predicted_y = predicted_y.reshape([int(height+1),int(width+1)])\n",
    "    test_y = test_y.reshape([int(height+1),int(width+1)])\n",
    "#     train_y = train_y.reshape([int(height+1),int(width+1)]) # for sending predicted shading texts to a partner\n",
    "    pre_vis =  copy.copy(predicted_y)\n",
    "    pre_vis_3 = cv2.merge([pre_vis,pre_vis,pre_vis])\n",
    "    pre_label = np.zeros_like(predicted_y, dtype=np.uint8)\n",
    "    pre_shading_label = np.zeros_like(predicted_y, dtype=np.uint8)\n",
    "    \n",
    "### modifying label to restore the symbol texts ###\n",
    "## output predicted image (Red:part of shading, Black: part of text)\n",
    "# Note: the format is BGR when using Open CV\n",
    "### restore unshaded txt and visualised images###\n",
    "    for i in range(int(height)):\n",
    "        for j in range(int(width)):\n",
    "#             if predicted_y[i,j] == 1 and train_y[i,j] ==1:\n",
    "            if predicted_y[i,j] == 1 and test_y[i,j] ==1:\n",
    "                pre_label[i,j] = 255 #1\n",
    "                pre_vis_3[i,j] = np.array([0,0,255]) # Color code #FF0000(Red)\n",
    "#             elif predicted_y[i,j] == 1 and train_y[i,j] ==2:\n",
    "            elif predicted_y[i,j] == 1 and test_y[i,j] ==2:\n",
    "                pre_label[i,j] = 255\n",
    "                pre_vis_3[i,j] = np.array([255,255,0]) # Color code #00FFFF(Cyan)\n",
    "#             elif predicted_y[i,j] == 2 and train_y[i,j]==2:\n",
    "            elif predicted_y[i,j] == 2 and test_y[i,j]==2:\n",
    "                pre_label[i,j] = 0 #1\n",
    "                pre_vis_3[i,j] = np.array([0,0,0]) # Color code #000000(Black)\n",
    "#             elif predicted_y[i,j] ==2 and train_y[i,j] == 1:\n",
    "            elif predicted_y[i,j] ==2 and test_y[i,j] == 1:\n",
    "                pre_label[i,j] = 0 #1\n",
    "                pre_vis_3[i,j] = np.array([0,140,255]) # Color code #FF8C00(DarkOrange)                \n",
    "            else:\n",
    "                pre_label[i,j] = 255 #1\n",
    "                pre_vis_3[i,j] = np.array([255,255,255]) # Color code #FFFFFF(White)\n",
    "####################################################\n",
    "\n",
    "### modifying label to restore the only shading texts ###\n",
    "    for k in range(int(height)):\n",
    "        for l in range(int(width)):\n",
    "            if predicted_y[k,l] != 1:\n",
    "                pre_shading_label[k,l] = 255\n",
    "            else:\n",
    "                pre_shading_label[k,l] = 0\n",
    "#########################################################\n",
    "    pre_label = pre_label.astype(int)# change type (float -> int) \n",
    "    pre_shading_label = pre_shading_label.astype(int)# change type (float -> int)\n",
    "    \n",
    "### output img SVC / extract only shading ### \n",
    "#     print(pre_vis_3) # for check output\n",
    "    cv2.imwrite(savedir+'/SVC/'+sheetname + 'SVC.png',pre_label) #output img using SVC\n",
    "    cv2.imwrite(savedir+'/SVC_vis/'+sheetname + 'SVC_vis.png',pre_vis_3) #output img using SVC visualisation\n",
    "    cv2.imwrite(savedir+'/shading/' +sheetname +'shading.png', pre_shading_label) #output shading img\n",
    "    print('Now create img file'+'['+str(num+1)+'/'+str(len(test_file))+']') # testfile comment\n",
    "#     print('Now create img file'+'['+str(num+1)+'/'+str(len(train_file))+']') # trainfile comment    \n",
    "#############################################\n",
    "\n",
    "# ## implement train file for checking overfitting ##\n",
    "# for num in range(len(train_file)):\n",
    "#     df = pd.read_csv(Path + train_file[num])\n",
    "#     train_X,train_y = df.iloc[:,:-1].values,df.iloc[:,-1].values\n",
    "#     # result\n",
    "#     predicted_y = clf4.predict(train_X)\n",
    "#     print('Output ' +str(train_file[num]) +'['+ str(num+1) + '/' + str(len(train_file))+']')\n",
    "#     # evaluation(accuracy)\n",
    "#     report = classification_report(train_y, predicted_y, output_dict=True)\n",
    "#     sheetname = os.path.splitext(os.path.basename(train_file[num]))[0]\n",
    "#     result = pd.DataFrame(report).transpose()\n",
    "#     if os.path.exists(savename):\n",
    "#         with pd.ExcelWriter(savename, engine=\"openpyxl\", mode=\"a\") as writer:\n",
    "#             result.to_excel(writer, sheet_name=sheetname)\n",
    "#     else:\n",
    "#         with pd.ExcelWriter(savename, engine=\"openpyxl\") as writer:\n",
    "#             result.to_excel(writer, sheet_name=sheetname)\n",
    "#####################################################\n",
    "\n",
    "print('Complete task')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
